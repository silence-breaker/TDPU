# 项目规格书：基于 FMQL30TAI 的 BitNet 端侧视障辅助系统

文档版本: V1.0  
硬件平台: 复旦微 FMQL30TAI (PS: ARM Cortex-A7/A53, PL: FPGA, NPU: Zhuge)  
核心模型: Microsoft BitNet b1.58 2B-4T (2-bit Weights, INT8 Activations)  
应用场景: 视障辅助导盲 (YOLO感知 -> LLM决策 -> 语音输出)

---

## 1. 系统架构概要 (System Architecture)

本系统采用 PS + PL + NPU 异构协同架构，通过共享内存 (Shared Memory) 进行数据交互。

* 感知层 (NPU): 运行 YOLOv5s (INT8)，负责提取环境中的物体标签与坐标。
* 认知层 (FPGA): 运行 BitNet 核心算子 (`BitLinear`)，利用 PL 端 DDR3 (4GB) 存储权重，加速矩阵乘法。
* 控制层 (PS CPU): 运行 Linux/Bare-metal C++ Runtime，负责：
  * Prompt 构建与 Tokenizer。
  * Attention/Softmax/RMSNorm 计算 (使用 ARM NEON 加速)。
  * DMA 数据搬运调度。
  * Quantization (FP32 <-> INT8) 数据转换。

---

## 2. 内存映射 (Memory Map)

> 参考: Icraft文档 `extensibility/customop.md` 4.2.1 系统架构

### 2.1 总线接口说明

FMQL30TAI 的 PS-PL 交互通过以下接口实现：

* **GP 口 (General Purpose)**: PS 总线从设备接口，CPU 通过 GP 口读写 PL 上的控制寄存器 (AXI-Lite)。
* **HP 口 (High Performance)**: PSDDR 控制器从设备接口，PL 模块作为主设备通过 HP 口读写 PSDDR。
* **PLDDR**: PL 模块可直接访问板载 PLDDR (4GB DDR3, 64-bit)。

### 2.2 GP 寄存器地址空间 (AXI-Lite 控制寄存器)

**GP0** (`0x4000_0000 ~ 0x7FFF_FFFF`):

| 分支 | 基地址 | 用途 |
| :--- | :--- | :--- |
| host_ctrl_upper | `0x4000_0000` | NPU 工作时钟调整 (系统已占用) |
| host_ctrl_lower | `0x4002_0000` | NPU 软核状态寄存器 (系统已占用) |
| ai_ra | `0x4004_0000` | NPU 硬核状态寄存器 (系统已占用) |
| **TDPU_ctrl** | **`0x4008_0000`** | **BitNet 加速器控制寄存器 (自定义, 详见 3.3 节)** |

自定义算子可用范围: `0x4008_0000 ~ 0x7FFF_FFFF` (约 1023 MB 地址空间)。

**GP1** (`0x8000_0000 ~ 0xBFFF_FFFF`):

| 分支 | 基地址 | 用途 |
| :--- | :--- | :--- |
| cdma_ctrl | `0x8000_0000` | CDMA 相关寄存器 (系统已占用) |
| image_make | `0x8000_0400` | ImageMake 相关寄存器 (系统已占用) |
| icore_post | `0x8000_0800` | IcorePostx 相关寄存器 (系统已占用) |
| cache | `0x8000_0C00` | Cache 相关寄存器 (系统已占用) |

自定义算子可用范围: `0x800C_0000 ~ 0xBFFF_FFFF` (约 1023 MB 地址空间)。

> 备注: NPU 占用 GP0 起始位置 512KB，CDMA 等模块占用 GP1 起始位置 768KB。挂载位置可调整，但占用空间固定。

### 2.3 数据存储地址空间 (DDR)

| 区域名称 | 存储位置 | 大小 (Size) | 访问方式 | 说明 |
| :--- | :--- | :--- | :--- | :--- |
| Model Weights | PLDDR | 600 MB | PL 直接访问; PS 通过驱动写入 | 存放预处理后的 BitNet 2-bit 压缩权重 (`.bin`) |
| Activation Buffer | PSDDR | 128 MB | PL 通过 HP 口读取; PS 直接读写 | 存放待发送给 FPGA 的 INT8 激活值 |
| KV Cache | PSDDR | 2 GB | PS 直接读写 | 存放 Attention 的 Key/Value 矩阵 (FP16/INT8) |
| Output Buffer | PSDDR | 64 MB | PL 通过 HP 口写入; PS 直接读取 | FPGA 计算结果 (INT32) 回写区域 |

> 说明: PLDDR 地址由 PL 端 DDR 控制器决定，PSDDR 地址由 Linux 内核分配 (通过 CMA 或 `dma_alloc_coherent`)。具体物理地址需在硬件集成时根据 Vivado 地址映射确定。

---

## 3. 数据协议定义 (Data Protocols)

所有软硬件接口必须严格遵守以下位级定义。

### 3.1 权重流格式 (Weight Stream - DDR to FPGA)

* 接口: AXI-Stream (64-bit Data Width)。
* 压缩率: 2-bit per weight -> 32 weights per 64-bit cycle。
* 编码映射 (Encoding):
  * `2'b01` : 0
  * `2'b10` : +1
  * `2'b00` : -1 (二进制 10)
  * `2'b11` : 0 (Padding/Reserved)
* 字节序: Little Endian (Bit[1:0] 对应 Index 0, Bit[63:62] 对应 Index 31)。

### 3.2 激活值格式 (Activation - Internal BRAM)

* 存储: FPGA 片内 Distributed RAM (LUTRAM)。
* 格式: INT8 (Signed char)。
* 范围: -128 ~ +127。
* 并行读取: 内部需支持单周期读取 256-bit (32 bytes)，以匹配 32 个并行权重。

### 3.3 控制寄存器 (AXI-Lite)

| 偏移 (Offset) | 名称 | 位宽 | 描述 |
| :--- | :--- | :--- | :--- |
| `0x00` | `CTRL` | 32 | Bit 0: `AP_START` (置1启动), Bit 1: `RESET` |
| `0x04` | `STATUS`| 32 | Bit 0: `AP_DONE` (为1表示计算完成), Bit 1: `IDLE` |
| `0x08` | `M_ROW` | 32 | 当前层输出维度 (Output Channels) |
| `0x0C` | `K_COL` | 32 | 当前层输入维度 (Input Features) |
| `0x10` | `DMA_LEN`| 32 | 权重传输总长度 (Bytes) |

---

## 4. 模块任务分解 (Development Tasks)

### 【任务 A】模型转换工具 (Python)

目标: 编写 `export_bitnet.py`，将 HuggingFace 模型转为板载二进制。
Prompt 指令:

1. 加载 `BitNet-b1.58-2B` PyTorch 模型。
2. 遍历所有 `BitLinear` 层，提取 INT8 权重。
3. 实现 `pack_weights` 函数：将每 4 个权重压缩进 1 个 `uint8`，或每 32 个权重压缩进 1 个 `uint64`。映射规则需符合 3.1 节 定义。
4. 将非 Linear 层 (Embedding, Norm) 保持 FP32 或 BF16 存入单独文件。
5. 输出 `model_config.h`，包含每一层的物理偏移地址 (Offset) 和形状 (Shape)。

### 【任务 B】FPGA 硬件逻辑 (SystemVerilog)

目标: 实现 `BitNet_Accelerator_IP`。
核心参数: `PARALLELISM = 32`, `AXI_WIDTH = 64`。
架构要求:

1. Input Stationary: 实现一个深度至少为 4096 的 Ping-Pong Buffer 或 LUTRAM，用于预加载输入向量 $X$ (INT8)。
2. Stream Unpacker: 编写组合逻辑，将 64-bit `s_axis_tdata` 实时解包为 32 个 `{-1, 0, 1}` 信号。
3. PE Array: 实例化 32 个计算单元。
    * 若权重为 +1: `Accumulator += Activation`
    * 若权重为 -1: `Accumulator -= Activation`
    * 若权重为 0 : 保持不变
    * 禁止使用 DSP 乘法器。
4. Adder Tree: 将 32 个 PE 的结果规约求和，并累加到 32-bit 输出寄存器。

### 【任务 C】运行时驱动 (C++ / ARM NEON)

目标: 编写高性能推理引擎 `inference_engine.cpp`。
Prompt 指令:

1. Memory: 使用 `mmap` 映射 `/dev/mem`，获取 FPGA 寄存器和 DDR 的虚拟地址。
2. NEON Optimization:
    * 实现 `void quantize_neon(float* src, int8_t* dst, int len)`：使用 `vld1q_f32`, `vmulq_f32`, `vcvtq_s32_f32` 指令，将 Attention 输出的 FP32 快速转为 INT8。
    * 实现 `void rmsnorm_neon(...)`：使用 NEON SIMD 加速平方和计算。
3. Execution Flow:
    * Step 1: CPU 计算 RMSNorm & Quantize。
    * Step 2: CPU 将 INT8 Activation 写入 FPGA BRAM。
    * Step 3: CPU 配置并启动 FPGA DMA (搬运权重)。
    * Step 4: CPU 轮询 FPGA `DONE` 信号，读取 INT32 结果并反量化。

### 【任务 D】系统集成 (Main Logic)

目标: 串联业务逻辑。
逻辑流:

1. 调用 NPU 接口运行 YOLOv5，获取 `vector<Object>`。
2. 构建 Prompt: `"Detected: [Object List]. Context: Blind user navigation. Warning:"`
3. 运行 Tokenizer (SentencePiece)。
4. 进入 LLM 循环：
    * Embedding (CPU)
    * Layer 0-25 Loop:
        * FPGA 加速 `Q_proj`, `K_proj`, `V_proj` (W1.58/A8)
        * CPU 计算 RoPE & Attention (FP32)
        * FPGA 加速 `O_proj`, `Gate`, `Up`, `Down` (W1.58/A8)
        * CPU 计算 Residual & Norm
    * LM_Head (CPU) -> Next Token
5. 输出文本 -> TTS 播放。

---

## 5. 验收标准 (Acceptance Criteria)

1. 资源占用: PL 资源使用率 <80%，时序收敛于 150MHz+。
2. 精度对齐: FPGA 算出的 Linear 层结果与 Python 模拟脚本的误差为 0 (整数无损计算)。
3. 性能指标: BitNet 推理速度在端侧达到 2-4 Tokens/s (满足实时语音播报需求)。
